{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SindhuPhani/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas \n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import array\n",
    "\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape,Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "#from keras.layers.pooling import GlobalAveragePooling1D\n",
    "#from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "#from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "19\n",
      "(114, 19, 250, 700, 1) (114, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time_steps=19\n",
    "# load the dataset\n",
    "dataframe = pandas.read_csv('./Trainold.csv')\n",
    "dataset = dataframe.values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "           \n",
    "#print(dataset)\n",
    "\n",
    "# we group by day so we can process a video at a time.\n",
    "grouped = dataframe.groupby(dataframe.VidName)\n",
    "\n",
    "per_vid = []\n",
    "for _, group in grouped:\n",
    "    per_vid.append(group)\n",
    "    \n",
    "    \n",
    "\n",
    "print(len(per_vid))\n",
    "\n",
    "\n",
    "\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "\n",
    "# generate sequences a vid at a time\n",
    "for i,vid in enumerate(per_vid):\n",
    "    histValuesList=[]\n",
    "    scoreList=[]\n",
    "    # if we have less than 20 datapoints for a vid we skip over the\n",
    "    # vid assuming something is missing in the raw data\n",
    "    \n",
    "    total = vid.iloc[:,4:20].values\n",
    "    vidImPath=vid.iloc[:,0:2].values    \n",
    "    \n",
    "    if len(total) < time_steps :\n",
    "        continue\n",
    "    scoreVal=vid[\"Score\"].values[0] + 1    \n",
    "    #max_total_for_vid = scoreVal.tolist()\n",
    "    max_total_for_vid = scoreVal.tolist()\n",
    "    \n",
    "    for i in range(0,time_steps):\n",
    "        videoName=vidImPath[i][0]\n",
    "        imgName=vidImPath[i][1]\n",
    "        path=\"./IMAGES/Train/\"+videoName+\"/\"+imgName\n",
    "        image = cv2.imread(path,0)\n",
    "        img_arr = img_to_array(image)\n",
    "        histValuesList.append(img_arr)\n",
    "        scoreList.append(max_total_for_vid)\n",
    "        \n",
    "    trainX.append(histValuesList)\n",
    "    trainY.append([max_total_for_vid])\n",
    "    #trainY.append(scoreList)\n",
    "\n",
    "\n",
    "print(len(trainX[0]))\n",
    "#trainX = np.array([np.array(xi) for xi in trainX])\n",
    "\n",
    "trainX=numpy.array(trainX)\n",
    "trainY=numpy.array(trainY)\n",
    "\n",
    "print(trainX.shape,trainY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "19\n",
      "(52, 19, 250, 700, 1) (52, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time_steps=19\n",
    "# load the dataset\n",
    "dataframe = pandas.read_csv('./Test.csv')\n",
    "dataset = dataframe.values\n",
    "\n",
    "#print(dataset)\n",
    "\n",
    "# we group by day so we can process a video at a time.\n",
    "grouped = dataframe.groupby(dataframe.VidName)\n",
    "\n",
    "per_vid = []\n",
    "for _, group in grouped:\n",
    "    per_vid.append(group)\n",
    "    \n",
    "    \n",
    "\n",
    "print(len(per_vid))\n",
    "\n",
    "\n",
    "\n",
    "testX=[]\n",
    "testY=[]\n",
    "\n",
    "# generate sequences a vid at a time\n",
    "for i,vid in enumerate(per_vid):\n",
    "    histValuesList=[]\n",
    "    scoreList=[]\n",
    "    # if we have less than 20 datapoints for a vid we skip over the\n",
    "    # vid assuming something is missing in the raw data\n",
    "    \n",
    "    total = vid.iloc[:,4:20].values\n",
    "\n",
    "    vidImPath=vid.iloc[:,0:2].values\n",
    "\n",
    "    \n",
    "    if len(total)<time_steps :\n",
    "        continue\n",
    "    scoreVal=vid[\"Score\"].values[0] + 1    \n",
    "    #max_total_for_vid = scoreVal.tolist()\n",
    "    max_total_for_vid = scoreVal.tolist()\n",
    "    \n",
    "    \n",
    "    for i in range(0,time_steps):\n",
    "        #histValuesList.append(total[i])\n",
    "        #print(\"Vid and Img name\")\n",
    "        #print(req[i][0],req[i][1])\n",
    "        videoName=vidImPath[i][0]\n",
    "        imgName=vidImPath[i][1]\n",
    "        path=\"./IMAGES/Test/\"+videoName+\"/\"+imgName\n",
    "        image = cv2.imread(path,0)\n",
    "        img_arr = img_to_array(image)\n",
    "        histValuesList.append(img_arr)\n",
    "        scoreList.append(max_total_for_vid)\n",
    "\n",
    "        \n",
    "    testX.append(histValuesList)\n",
    "    testY.append([max_total_for_vid])\n",
    "    #testY.append(scoreList)\n",
    "\n",
    "\n",
    "print(len(testX[0]))\n",
    "#trainX = np.array([np.array(xi) for xi in trainX])\n",
    "\n",
    "testX=numpy.array(testX)\n",
    "testY=numpy.array(testY)\n",
    "\n",
    "print(testX.shape,testY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 19, 250, 700, 1) (114, 1)\n",
      "(52, 19, 250, 700, 1) (52, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX=numpy.array(trainX)\n",
    "trainX=trainX.reshape(-1,250,700,1)\n",
    "\n",
    "trainX=trainX/255\n",
    "\n",
    "trainX=trainX.reshape(-1,19,250,700,1)\n",
    "print(trainX.shape,trainY.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testX=numpy.array(testX)\n",
    "testX=testX.reshape(-1,250,700,1)\n",
    "\n",
    "testX=testX/255\n",
    "testX=testX.reshape(-1,19,250,700,1)\n",
    "print(testX.shape,testY.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SindhuPhani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(250, 700,..., activation=\"relu\")`\n",
      "/Users/SindhuPhani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "/Users/SindhuPhani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 19, 248, 698, 16)  160       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 19, 124, 349, 16)  0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 19, 122, 347, 32)  4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 19, 61, 173, 32)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 19, 59, 171, 64)   18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 19, 29, 85, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 19, 157760)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 19, 256)           40386816  \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 19, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 19, 128)           32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 19, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 19, 64)            8256      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20)                6800      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 40,458,085\n",
      "Trainable params: 40,458,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input ,Dense, Dropout, Activation, LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "timesteps=20; # 20 or frames created\n",
    "number_of_samples=114; # total no of videos\n",
    "nb_samples=number_of_samples;\n",
    "frame_row=250; # image height\n",
    "frame_col=700; # img width\n",
    "channels=1; # rgb \n",
    "\n",
    "nb_epoch=1;\n",
    "batch_size=timesteps;\n",
    "\n",
    "sgd1 = optimizers.SGD(lr=0.005)\n",
    "\n",
    "\n",
    "nb_epoch=1;\n",
    "batch_size=timesteps;\n",
    "\n",
    "\n",
    "\n",
    "model=Sequential();                          \n",
    "\n",
    "#model.add(TimeDistributed(Convolution2D(32, 3, 3, border_mode='same'), input_shape=trainX.shape[1:]))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Convolution2D(16, 3, 3, input_shape=(250,700,1), activation='relu'),input_shape=trainX.shape[1:]))    \n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Convolution2D(32, 3, 3, activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Convolution2D(64, 3, 3, activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(.5)))\n",
    "model.add(TimeDistributed(Dense(128, activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(.25)))\n",
    "model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "#model.add(Flatten())\n",
    "#model.add(TimeDistributed(Dense(1)))\n",
    "#model.add(Flatten())\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(1))\n",
    "#model.compile(optimizer=Adam(lr=1e-04), loss='mean_squared_error') \n",
    "\n",
    "model.compile(loss='mse', optimizer=sgd1, metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "114/114 [==============================] - 3898s 34s/step - loss: 2.2347 - mean_squared_error: 2.2347\n",
      "Epoch 2/5\n",
      "114/114 [==============================] - 4965s 44s/step - loss: 1.2259 - mean_squared_error: 1.2259\n",
      "Epoch 3/5\n",
      "114/114 [==============================] - 6323s 55s/step - loss: 1.0571 - mean_squared_error: 1.0571\n",
      "Epoch 4/5\n",
      "114/114 [==============================] - 5391s 47s/step - loss: 1.0367 - mean_squared_error: 1.0367\n",
      "Epoch 5/5\n",
      "114/114 [==============================] - 4997s 44s/step - loss: 1.0241 - mean_squared_error: 1.0241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1b516cf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, batch_size=batch_size, epochs=5, verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 1)\n",
      "(52, 1)\n",
      "Test Score: 1.57 MSE\n",
      "RMSE Score: 1.25 rmse\n",
      "[0] [1.7004896]\n",
      "[0] [1.6688989]\n",
      "[0] [1.6393205]\n",
      "[0] [1.7110369]\n",
      "[1] [1.7345065]\n",
      "[3] [1.7472938]\n",
      "[0] [1.7391174]\n",
      "[4] [1.7410866]\n",
      "[0] [1.7349585]\n",
      "[0] [1.7454833]\n",
      "[3] [1.7415594]\n",
      "[4] [1.7304785]\n",
      "[1] [1.6978133]\n",
      "[2] [1.6363839]\n",
      "[1] [1.6828238]\n",
      "[2] [1.6968132]\n",
      "[1] [1.6957049]\n",
      "[2] [1.6960124]\n",
      "[1] [1.7078899]\n",
      "[0] [1.7344962]\n",
      "[0] [1.7391795]\n",
      "[0] [1.724224]\n",
      "[2] [1.7286818]\n",
      "[0] [1.6979288]\n",
      "[0] [1.7262517]\n",
      "[0] [1.7169774]\n",
      "[2] [1.7157333]\n",
      "[1] [1.7038007]\n",
      "[3] [1.7112952]\n",
      "[0] [1.7025791]\n",
      "[0] [1.7115589]\n",
      "[0] [1.7044338]\n",
      "[0] [1.7321706]\n",
      "[2] [1.6998719]\n",
      "[2] [1.7007699]\n",
      "[1] [1.6950885]\n",
      "[1] [1.6839781]\n",
      "[2] [1.6525481]\n",
      "[1] [1.66793]\n",
      "[2] [1.7143855]\n",
      "[1] [1.698237]\n",
      "[1] [1.7075626]\n",
      "[4] [1.7361964]\n",
      "[1] [1.6878743]\n",
      "[1] [1.7196648]\n",
      "[2] [1.6397696]\n",
      "[0] [1.6517644]\n",
      "[1] [1.6654024]\n",
      "[1] [1.6913015]\n",
      "[1] [1.6910542]\n",
      "[2] [1.6325033]\n",
      "[2] [1.702132]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "pred=model.predict(testX)\n",
    "\n",
    "print(pred.shape)\n",
    "print(testY.shape)\n",
    "\n",
    "\n",
    "\n",
    "# calculate root mean squared error\n",
    "#trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "#print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = mean_squared_error(testY, pred)\n",
    "print('Test Score: %.2f MSE' % (testScore))\n",
    "\n",
    "#maeScore = root_mean_squared_error(testY, pred)\n",
    "#print('RMSE Score: %.2f MAE' % (maeScore))\n",
    "\n",
    "rmse = np.sqrt(((pred - testY) ** 2).mean(axis=0))\n",
    "print('RMSE Score: %.2f rmse' % (rmse))\n",
    "\n",
    "for i in range(0,len(pred)):\n",
    "    \n",
    "    print(testY[i],pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save(filepath=\"./CNNLSTM.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
